{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captura y almacenamiento de la información\n",
    "Profesores: MSc Oscar Bría - Mg Javier Bazzocco\n",
    "\n",
    "\n",
    "## Introducción y objetivos\n",
    "\n",
    "Twitter es una de las mayores redes sociales en cuanto al flujo de información. Dada su gran popularidad entre personas de distintas ubicaciones geográficas, edades, aspectos sociales, etc...en esta red puede encontrarse información de las mas diversas areas (politica, deportes, ciencia, chismes, etc...). Si bien un tweet puede tener un número bajo de caracteres, la información suele estar bien resumida y esto lo hace una herramienta ágil para la búsqueda inmediata de información sobre algún tema particular. Por ejemplo, basta buscar con un hashtag (#palabraclave) sobre un tema de interés para que tengamos la información mas actualizada sobre esa palabra clave. Hoy en día no solo las personas utilizan estas redes sociales para transmitir información, sino que también lo hacen las empresas, instituciones educativas y científicas, gobiernos, etc...\n",
    "\n",
    "\n",
    "\n",
    "En este contexto, el objetivo de esta notebook es analizar si hay alguna respuesta del público de Twitter a un evento natural como un terremoto. Claramente esto va a depender de la ubicación del evento sísmico y las personas cercanas a este punto que posteen algo en sus cuentas de este red social. La información de los eventos sísmicos se obtiene a partir de una base de datos siendo de interés las coordenas geográficas y magnitud del sismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comenzemos...\n",
    "\n",
    "Para este análisis se utilizará el lenguaje de programación Python y la librería Tweepy para interactuar con la API de Tweeter. También se utilizarán otras como Pandas y csv para el manejo de los datos. Los datos serán obtenidos de alguna institución que permite el acceso libre a los datos y serán almacenados en MongoDB. Utilizo MongoDB Atlas, esto es la base de datos como servicio de MongoDB (DaS) el cual me permite tener una cuenta gratuita con un espacio limitado pero suficiente para este trabajo. https://www.mongodb.com/cloud/atlas/signup?v=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las librerías \n",
    "import tweepy as tw # para interactuar con la API de Twitter\n",
    "import pandas as pd # para manipular datos\n",
    "import csv          # archivos comma separation value\n",
    "import json         # archivos JSON\n",
    "#!pip install dnspython # para instalar librerías para poder concetar con MongoDB \n",
    "#!pip install pymongo   # permite interacción entre MongoDB y Python  \n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"\")# completar con sus datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['cluster0-shard-00-01-rkxjw.mongodb.net:27017', 'cluster0-shard-00-02-rkxjw.mongodb.net:27017', 'cluster0-shard-00-00-rkxjw.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, retrywrites=True, w='majority', authsource='admin', replicaset='Cluster0-shard-0', ssl=True), 'Prueba0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = client.get_database('Prueba0') # Me meto en la base de datos Prueba0 que generé en mi cluster en MongoDB Atlas.\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo el archivo JSON con la información de los terremotos.\n",
    "\n",
    "collection_sismos = db['Sismos'] # coleccion donde quiero guardar el documento\n",
    "\n",
    "with open('query_usgs.json') as f:\n",
    "    file_data = json.load(f)\n",
    "\n",
    "# Para insertar UN documento:\n",
    "#collection_sismos.insert_one(file_data) #Obs: Si corro esta celda carga el dato en la colección en mi base de datos cluster0\n",
    "# Para insertar VARIOS documentos:\n",
    "#collection_sismos.insert_many(file_data)\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me canse de probar cosas...no funciona. :(\n",
    "# build a Python dictionary for query\n",
    "#query = {\"mag\" : 4.9}\n",
    "\n",
    "#documents = list(collection_sismos.find(query))\n",
    "#for doc in documents:\n",
    "#    print (\"\\ndoc _id:\", doc[\"_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien...ya tenemos la información de los terremotos desde Mongo. Para poder acceder a la información de Twitter hay que tener una cuenta en twitter developers (https://developer.twitter.com/en). Ahí se crea una aplicación luego de un par de preguntas sobre el objetivo de la App y listo! Se necesitan 4 cosas de la aplicacion de twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= 'sus datos'\n",
    "consumer_secret= 'sus datos'\n",
    "access_token= 'sus datos'\n",
    "access_token_secret= 'sus datos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear la conexión..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que está todo preparado para interactuar con Twitter podemos comenzar a trabajar para lograr nuestro objetivo. Debe de considerarse que nuestro planeta está en constante movimiento y por ende se registran muchísimos terremotos por día. No obstante, son los de magintudes grandes y algunos medianos, con un escenario geológico particular, los que generalmente se pueden percibir. Cuando este es el caso, se ha visto y es de esperarse, las personas suelen postear en sus cuentas de redes sociales sobre como y/o cuando percibieron el movimiento.\n",
    "\n",
    "Para ilustrar esto se puede ver facilmente los últimos tweets del INSTITUTO NACIONAL DE PREVENCIÓN SÍSMICA ( www.inpres.gob.ar ). Es inmediato que las magnitudes registradas por los sismógrafos, en general, no son perceptibles por los humanos. Puede haber excepciones! Por otro lado, la mayoría de las instituciones y/o cuentas que comparten este tipo de información no suelen dar la ubicación geográfica del evento. En el mejor de los casos tendremos esta información de ubicación en los niveles de provincia o estado. Tal vez con suerte, de localidad o ciudad. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha detectado un #sismo de 2.5 ML en La Rioja. \n",
      "\n",
      "Más info en el enalce. \n",
      "https://t.co/rOXRfppMII\n",
      "Se ha detectado un #sismo de 2.8 ML en Cordoba. \n",
      "\n",
      "Más info en el enalce. \n",
      "https://t.co/zK7ih4tgLq\n",
      "Se ha detectado un #sismo de 2.6 ML en San Juan. \n",
      "\n",
      "Más info en el enalce. \n",
      "https://t.co/r8yiZwFNGW\n",
      "Se ha detectado un #sismo de 2.8 ML en Jujuy. \n",
      "\n",
      "Más info en el enalce. \n",
      "https://t.co/lZXt9KpQPi\n",
      "Se ha detectado un #sismo de 2.6 ML en La Rioja. \n",
      "\n",
      "Más info en el enalce. \n",
      "https://t.co/I94EZZ42OY\n",
      "Se ha detectado un #sismo de 2.9 ML en Salta. \n",
      "\n",
      "Más info en el enalce. \n",
      "https://t.co/jSNPDRyQfP\n",
      "Se ha detectado un #sismo de 2.8 ML en San Juan. \n",
      "\n",
      "Más info en el enalce. \n",
      "https://t.co/u4vnLZFksu\n",
      "Se ha detectado un #sismo de 2.5 ML en San Juan. \n",
      "\n",
      "Más info en el enalce. \n",
      "https://t.co/vhI4tb2esB\n",
      "Se ha detectado un #sismo de 2.9 ML en Salta. \n",
      "\n",
      "Más info en el enalce. \n",
      "https://t.co/SQH7ICvKZs\n",
      "Se ha detectado un #sismo de 3.2 ML en Salta. \n",
      "\n",
      "Más info en el enalce. \n",
      "https://t.co/VswMvm9JXd\n"
     ]
    }
   ],
   "source": [
    "# usuario de twitter\n",
    "name = 'inpres_sismos'\n",
    "#name = 'USGSBigQuakes'\n",
    "nro_tweets = 10 # cantidad de tweets que queremos ver\n",
    "\n",
    "resultado = api.user_timeline(id=name, count=nro_tweets) # interacción con Twitter\n",
    "\n",
    "for tweet in resultado: \n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es inmediato que la mayoría de las magnitudes registradas por los sismógrafos no son perceptibles por los humanos. Por otro lado, la mayoría de las instituciones y/o cuentas que comparten este tipo de información no suelen dar la ubicación geográfica del evento. En el mejor de los casos tendremos esta información de ubicación en los niveles de provincia o estado. Tal vez con suerte, de la localidad o ciudad. Por esto, para ver si es posible o no ver la reacción de las personas a un evento de este tipo, es necesario contar con los datos de alguna institución. En el siguiente link puede encontrarse el catalogo del USGS https://earthquake.usgs.gov/earthquakes/search/ , el cual permite bajar los datos en diferentes formatos y son los que fueron cargados en la BD anteriormente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como mencioné, probablemente se pueda encontrar los tweets relacionados con algún terremoto de magnitud alta. Para esto buscamos en la base de datos por el terremoto de mayor magnitud y nos interesa sus coordenadas geográficas para buscar en Twitter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acá iría el query para buscar el terremoto de mayor magnitud y guardar en variables la latitud y longitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe de tener en cuenta de que una coordenada geográfica es un punto en nuestro planeta por lo que si queremos buscar tweets, debemos buscar mas que en el epicentro del evento sísmico en los alrededores. La API de Tweeter mediante Tweepy nos permite elegir el radio entorno a este punto donde queremos ver los tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta info no va en la version final...es para probar que funcione.\n",
    "# posición de la ubicación de interés. En este caso Buenos Aires y San Juan, Argentina:\n",
    "\n",
    "latitud = -34.6131516#    -31.5375004#\n",
    "longitud = -58.3772316#   -68.5363922 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio = 700             # Rango de búsqueda en km en torno a la posición dada.\n",
    "max_res = 10            # numero maximo de resultados que quiero ver.\n",
    "outfile = \"output.csv\"  # por si quiero guardar los datos en un archivo tipo csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo importante para este análisis es la elección de la palabra clave para buscar los tweets. Tener en cuenta que se pueden obtener los tweets de hasta los últimos 7 días."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar2san</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>Va a venir la NASA,en serio República oriental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LaSolapaOk</td>\n",
       "      <td>Entre Ríos, Argentina</td>\n",
       "      <td>#Entrerrianos | #ColoColo 🎉🎈\\n\\nHoy el conjunt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user               location  \\\n",
       "0     mar2san                Uruguay   \n",
       "1  LaSolapaOk  Entre Ríos, Argentina   \n",
       "\n",
       "                                              Tweets  \n",
       "0  Va a venir la NASA,en serio República oriental...  \n",
       "1  #Entrerrianos | #ColoColo 🎉🎈\\n\\nHoy el conjunt...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_words = \"#terremoto\"+ \"-filter:retweets\" \n",
    "desde = \"2020-4-18\" # la fecha (ano/mes/dia) desde...\n",
    "hasta =  \"2020-4-26\" # hasta...\n",
    "\n",
    "# Extraemos los tweets...\n",
    "tweets = tw.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"es\",\n",
    "              geocode = \"%f,%f,%dkm\" % (latitud, longitud, radio),\n",
    "              since=desde,\n",
    "              until=hasta).items(max_res)\n",
    "tweets\n",
    "\n",
    "#[tweet.text for tweet in tweets]\n",
    "users_locs = [[tweet.user.screen_name, tweet.user.location, tweet.text] for tweet in tweets]\n",
    "users_locs\n",
    "\n",
    "tweet_text = pd.DataFrame(data=users_locs, \n",
    "                    columns=['user', \"location\",\"Tweets\"])\n",
    "tweet_text#.to_csv('out.csv',index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
