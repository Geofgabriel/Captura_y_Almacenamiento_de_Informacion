{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captura y almacenamiento de la informaci칩n\n",
    "Profesores: MSc Oscar Br칤a - Mg Javier Bazzocco\n",
    "\n",
    "\n",
    "## Introducci칩n y objetivos\n",
    "\n",
    "Twitter es una de las mayores redes sociales en cuanto al flujo de informaci칩n. Dada su gran popularidad entre personas de distintas ubicaciones geogr치ficas, edades, aspectos sociales, etc...en esta red puede encontrarse informaci칩n de las mas diversas areas (politica, deportes, ciencia, chismes, etc...). Si bien un tweet puede tener un n칰mero bajo de caracteres, la informaci칩n suele estar bien resumida y esto lo hace una herramienta 치gil para la b칰squeda inmediata de informaci칩n sobre alg칰n tema particular. Por ejemplo, basta buscar con un hashtag (#palabraclave) sobre un tema de inter칠s para que tengamos la informaci칩n mas actualizada sobre esa palabra clave. Hoy en d칤a no solo las personas utilizan estas redes sociales para transmitir informaci칩n, sino que tambi칠n lo hacen las empresas, instituciones educativas y cient칤ficas, gobiernos, etc...\n",
    "\n",
    "\n",
    "\n",
    "En este contexto, el objetivo de esta notebook es analizar si hay alguna respuesta del p칰blico de Twitter a un evento natural como un terremoto. Claramente esto va a depender de la ubicaci칩n del evento s칤smico y las personas cercanas a este punto que posteen algo en sus cuentas de este red social. La informaci칩n de los eventos s칤smicos se obtiene a partir de una base de datos siendo de inter칠s las coordenas geogr치ficas y magnitud del sismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comenzemos...\n",
    "\n",
    "Para este an치lisis se utilizar치 el lenguaje de programaci칩n Python y la librer칤a Tweepy para interactuar con la API de Tweeter. Tambi칠n se utilizar치n otras como Pandas y csv para el manejo de los datos. Los datos ser치n obtenidos de alguna instituci칩n que permite el acceso libre a los datos y ser치n almacenados en MongoDB. Utilizo MongoDB Atlas, esto es la base de datos como servicio de MongoDB (DaS) el cual me permite tener una cuenta gratuita con un espacio limitado pero suficiente para este trabajo. https://www.mongodb.com/cloud/atlas/signup?v=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las librer칤as \n",
    "import tweepy as tw # para interactuar con la API de Twitter\n",
    "import pandas as pd # para manipular datos\n",
    "import csv          # archivos comma separation value\n",
    "import json         # archivos JSON\n",
    "#!pip install dnspython # para instalar librer칤as para poder concetar con MongoDB \n",
    "#!pip install pymongo   # permite interacci칩n entre MongoDB y Python  \n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"\")# completar con sus datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['cluster0-shard-00-01-rkxjw.mongodb.net:27017', 'cluster0-shard-00-02-rkxjw.mongodb.net:27017', 'cluster0-shard-00-00-rkxjw.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, retrywrites=True, w='majority', authsource='admin', replicaset='Cluster0-shard-0', ssl=True), 'Prueba0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = client.get_database('Prueba0') # Me meto en la base de datos Prueba0 que gener칠 en mi cluster en MongoDB Atlas.\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo el archivo JSON con la informaci칩n de los terremotos.\n",
    "\n",
    "collection_sismos = db['Sismos'] # coleccion donde quiero guardar el documento\n",
    "\n",
    "with open('query_usgs.json') as f:\n",
    "    file_data = json.load(f)\n",
    "\n",
    "# Para insertar UN documento:\n",
    "#collection_sismos.insert_one(file_data) #Obs: Si corro esta celda carga el dato en la colecci칩n en mi base de datos cluster0\n",
    "# Para insertar VARIOS documentos:\n",
    "#collection_sismos.insert_many(file_data)\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me canse de probar cosas...no funciona. :(\n",
    "# build a Python dictionary for query\n",
    "#query = {\"mag\" : 4.9}\n",
    "\n",
    "#documents = list(collection_sismos.find(query))\n",
    "#for doc in documents:\n",
    "#    print (\"\\ndoc _id:\", doc[\"_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien...ya tenemos la informaci칩n de los terremotos desde Mongo. Para poder acceder a la informaci칩n de Twitter hay que tener una cuenta en twitter developers (https://developer.twitter.com/en). Ah칤 se crea una aplicaci칩n luego de un par de preguntas sobre el objetivo de la App y listo! Se necesitan 4 cosas de la aplicacion de twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= 'sus datos'\n",
    "consumer_secret= 'sus datos'\n",
    "access_token= 'sus datos'\n",
    "access_token_secret= 'sus datos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear la conexi칩n..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que est치 todo preparado para interactuar con Twitter podemos comenzar a trabajar para lograr nuestro objetivo. Debe de considerarse que nuestro planeta est치 en constante movimiento y por ende se registran much칤simos terremotos por d칤a. No obstante, son los de magintudes grandes y algunos medianos, con un escenario geol칩gico particular, los que generalmente se pueden percibir. Cuando este es el caso, se ha visto y es de esperarse, las personas suelen postear en sus cuentas de redes sociales sobre como y/o cuando percibieron el movimiento.\n",
    "\n",
    "Para ilustrar esto se puede ver facilmente los 칰ltimos tweets del INSTITUTO NACIONAL DE PREVENCI칍N S칈SMICA ( www.inpres.gob.ar ). Es inmediato que las magnitudes registradas por los sism칩grafos, en general, no son perceptibles por los humanos. Puede haber excepciones! Por otro lado, la mayor칤a de las instituciones y/o cuentas que comparten este tipo de informaci칩n no suelen dar la ubicaci칩n geogr치fica del evento. En el mejor de los casos tendremos esta informaci칩n de ubicaci칩n en los niveles de provincia o estado. Tal vez con suerte, de localidad o ciudad. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha detectado un #sismo de 2.5 ML en La Rioja. \n",
      "\n",
      "M치s info en el enalce. \n",
      "https://t.co/rOXRfppMII\n",
      "Se ha detectado un #sismo de 2.8 ML en Cordoba. \n",
      "\n",
      "M치s info en el enalce. \n",
      "https://t.co/zK7ih4tgLq\n",
      "Se ha detectado un #sismo de 2.6 ML en San Juan. \n",
      "\n",
      "M치s info en el enalce. \n",
      "https://t.co/r8yiZwFNGW\n",
      "Se ha detectado un #sismo de 2.8 ML en Jujuy. \n",
      "\n",
      "M치s info en el enalce. \n",
      "https://t.co/lZXt9KpQPi\n",
      "Se ha detectado un #sismo de 2.6 ML en La Rioja. \n",
      "\n",
      "M치s info en el enalce. \n",
      "https://t.co/I94EZZ42OY\n",
      "Se ha detectado un #sismo de 2.9 ML en Salta. \n",
      "\n",
      "M치s info en el enalce. \n",
      "https://t.co/jSNPDRyQfP\n",
      "Se ha detectado un #sismo de 2.8 ML en San Juan. \n",
      "\n",
      "M치s info en el enalce. \n",
      "https://t.co/u4vnLZFksu\n",
      "Se ha detectado un #sismo de 2.5 ML en San Juan. \n",
      "\n",
      "M치s info en el enalce. \n",
      "https://t.co/vhI4tb2esB\n",
      "Se ha detectado un #sismo de 2.9 ML en Salta. \n",
      "\n",
      "M치s info en el enalce. \n",
      "https://t.co/SQH7ICvKZs\n",
      "Se ha detectado un #sismo de 3.2 ML en Salta. \n",
      "\n",
      "M치s info en el enalce. \n",
      "https://t.co/VswMvm9JXd\n"
     ]
    }
   ],
   "source": [
    "# usuario de twitter\n",
    "name = 'inpres_sismos'\n",
    "#name = 'USGSBigQuakes'\n",
    "nro_tweets = 10 # cantidad de tweets que queremos ver\n",
    "\n",
    "resultado = api.user_timeline(id=name, count=nro_tweets) # interacci칩n con Twitter\n",
    "\n",
    "for tweet in resultado: \n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es inmediato que la mayor칤a de las magnitudes registradas por los sism칩grafos no son perceptibles por los humanos. Por otro lado, la mayor칤a de las instituciones y/o cuentas que comparten este tipo de informaci칩n no suelen dar la ubicaci칩n geogr치fica del evento. En el mejor de los casos tendremos esta informaci칩n de ubicaci칩n en los niveles de provincia o estado. Tal vez con suerte, de la localidad o ciudad. Por esto, para ver si es posible o no ver la reacci칩n de las personas a un evento de este tipo, es necesario contar con los datos de alguna instituci칩n. En el siguiente link puede encontrarse el catalogo del USGS https://earthquake.usgs.gov/earthquakes/search/ , el cual permite bajar los datos en diferentes formatos y son los que fueron cargados en la BD anteriormente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como mencion칠, probablemente se pueda encontrar los tweets relacionados con alg칰n terremoto de magnitud alta. Para esto buscamos en la base de datos por el terremoto de mayor magnitud y nos interesa sus coordenadas geogr치ficas para buscar en Twitter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ac치 ir칤a el query para buscar el terremoto de mayor magnitud y guardar en variables la latitud y longitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe de tener en cuenta de que una coordenada geogr치fica es un punto en nuestro planeta por lo que si queremos buscar tweets, debemos buscar mas que en el epicentro del evento s칤smico en los alrededores. La API de Tweeter mediante Tweepy nos permite elegir el radio entorno a este punto donde queremos ver los tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta info no va en la version final...es para probar que funcione.\n",
    "# posici칩n de la ubicaci칩n de inter칠s. En este caso Buenos Aires y San Juan, Argentina:\n",
    "\n",
    "latitud = -34.6131516#    -31.5375004#\n",
    "longitud = -58.3772316#   -68.5363922 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio = 700             # Rango de b칰squeda en km en torno a la posici칩n dada.\n",
    "max_res = 10            # numero maximo de resultados que quiero ver.\n",
    "outfile = \"output.csv\"  # por si quiero guardar los datos en un archivo tipo csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo importante para este an치lisis es la elecci칩n de la palabra clave para buscar los tweets. Tener en cuenta que se pueden obtener los tweets de hasta los 칰ltimos 7 d칤as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar2san</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>Va a venir la NASA,en serio Rep칰blica oriental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LaSolapaOk</td>\n",
       "      <td>Entre R칤os, Argentina</td>\n",
       "      <td>#Entrerrianos | #ColoColo 游꿀游꾿\\n\\nHoy el conjunt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user               location  \\\n",
       "0     mar2san                Uruguay   \n",
       "1  LaSolapaOk  Entre R칤os, Argentina   \n",
       "\n",
       "                                              Tweets  \n",
       "0  Va a venir la NASA,en serio Rep칰blica oriental...  \n",
       "1  #Entrerrianos | #ColoColo 游꿀游꾿\\n\\nHoy el conjunt...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_words = \"#terremoto\"+ \"-filter:retweets\" \n",
    "desde = \"2020-4-18\" # la fecha (ano/mes/dia) desde...\n",
    "hasta =  \"2020-4-26\" # hasta...\n",
    "\n",
    "# Extraemos los tweets...\n",
    "tweets = tw.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"es\",\n",
    "              geocode = \"%f,%f,%dkm\" % (latitud, longitud, radio),\n",
    "              since=desde,\n",
    "              until=hasta).items(max_res)\n",
    "tweets\n",
    "\n",
    "#[tweet.text for tweet in tweets]\n",
    "users_locs = [[tweet.user.screen_name, tweet.user.location, tweet.text] for tweet in tweets]\n",
    "users_locs\n",
    "\n",
    "tweet_text = pd.DataFrame(data=users_locs, \n",
    "                    columns=['user', \"location\",\"Tweets\"])\n",
    "tweet_text#.to_csv('out.csv',index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
